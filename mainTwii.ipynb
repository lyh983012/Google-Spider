{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc6efe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442aa707",
   "metadata": {},
   "source": [
    "https://www.scraping-bot.io/web-scraping-documentation/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a610542",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import requests\n",
    "import json\n",
    "from time import sleep\n",
    "\n",
    "username = 'ordinarabbit'\n",
    "apiKey = 'C4EIAF9XMpr7fiwVJMBWZbBDg'\n",
    "scraper = 'facebookPost'\n",
    "url = 'https://facebook.com/search/posts/?q=bar%20roomfs%20sds'\n",
    "\n",
    "apiEndPoint = \"http://api.scraping-bot.io/scrape/data-scraper\"\n",
    "apiEndPointResponse = \"http://api.scraping-bot.io/scrape/data-scraper-response?\"\n",
    "\n",
    "payload = json.dumps({\"url\": url, \"scraper\": scraper})\n",
    "headers = {\n",
    "    'Content-Type': \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", apiEndPoint, data=payload, auth=(username, apiKey), headers=headers)\n",
    "print(response)\n",
    "if response.status_code == 200:\n",
    "    print(response.json())\n",
    "    print(response.json()[\"responseId\"])\n",
    "    responseId = response.json()[\"responseId\"]\n",
    "\n",
    "    pending = True\n",
    "    while pending:\n",
    "        # sleep 5s between each loop, social-media scraping can take quite long to complete\n",
    "        # so there is no point calling the api quickly as we will return an error if you do so\n",
    "        sleep(5)\n",
    "        finalResponse = requests.request(\"GET\", apiEndPointResponse + \"scraper=\" + scraper + \"&responseId=\" + responseId\n",
    "                                         , auth=(username, apiKey))\n",
    "        result = finalResponse.json()\n",
    "        if type(result) is list:\n",
    "            pending = False\n",
    "            print(finalResponse.text)\n",
    "        elif type(result) is dict:\n",
    "            if \"status\" in result and result[\"status\"] == \"pending\":\n",
    "                print(result[\"message\"])\n",
    "                continue\n",
    "            elif result[\"error\"] is not None:\n",
    "                pending = False\n",
    "                print(json.dumps(result, indent=4))\n",
    "\n",
    "else:\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b441dbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFound",
     "evalue": "Content not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q9/w0l08v3s18n2z_gsznmbq7hh0000gn/T/ipykernel_73738/2635461863.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_posts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mother'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoockies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyprojects/Google-Spider/fb_scraper/facebook_scraper.py\u001b[0m in \u001b[0;36m_generic_get_posts\u001b[0;34m(self, extract_post_fn, iter_pages_fn, page_limit, options, remove_source, latest_date, max_past_limit, **kwargs)\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting to iterate pages\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_pages_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting posts from page %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mpost_element\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyprojects/Google-Spider/fb_scraper/page_iterators.py\u001b[0m in \u001b[0;36mgeneric_iter_pages\u001b[0;34m(start_url, page_parser_cls, request_fn, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Requesting page from: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyprojects/Google-Spider/fb_scraper/facebook_scraper.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnot_found_titles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"error\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnexpectedResponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your request couldn't be processed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFound\u001b[0m: Content not found"
     ]
    }
   ],
   "source": [
    "from facebook_scraper import get_posts\n",
    "coockies={'c_user':'100089571227670',\n",
    "          'preesnce':'C%7B%22t3%22%3A%5B%5D%2C%22utc3%22%3A1675337611665%2C%22v%22%3A1%7D',\n",
    "          'dpr':'1',\n",
    "          'wd':'1648x440',\n",
    "          'sb':'A4rUY7cdw5Z-Dk6x1ZsU6OrI',\n",
    "          'datr':'A4rUYwJzo_IxS2Fx6uPQIA5P',\n",
    "          'fr':'0O2qJVGQoIzDJ20MG.AWWBXIh2XgcH6ly1ftyoFsKNAg8.Bj25Y5.D1.AAA.0.0.Bj25-G.AWXuYDnbsvs',\n",
    "          'xs':'46%3Aduzj5ZvUngLkZw%3A2%3A1674873361%3A-1%3A-1%3A%3AAcVKUc0PGNXT7hg-n3Su6dZrLCt2F6iRPaldCLgRUg'}\n",
    "\n",
    "agent =  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:65.0) Gecko/20100101 Firefox/65.0\"\n",
    "\n",
    "\n",
    "for post in get_posts('nintendo', agent=agent, pages=4,cookies=coockies):\n",
    "    print(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1751669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871ed8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
